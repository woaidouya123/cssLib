<!DOCTYPE html>

<head>
  <title>视频转文字</title>
  <meta charset="utf-8">
  <style>
    body{
      overflow: hidden;
      padding: 0px;
    }
    #start{
      border:none;
      outline: none;
      position: absolute;
      left: 50%;
      top: 50%;
      transform: translateX(-50%) translateY(-50%);
      background-color: transparent;
    }
    .container{
      position: absolute;
      z-index: 10;
      width: 100%;
      height: 100%;
      top: 0px;
      left: 0px;
      background: rgba(255, 255, 255, .95);
    }
    .container .text-content{
      display: flex;
      justify-content: center;
    }
    .text-content div{
      font-size: 12px;
      line-height: 12px;
      display: inline-block;
      vertical-align: top;
      margin: 0 20px;
    }
    #audio-left{
      text-align: right;
      flex: 1;
    }
    #audio-right{
      text-align: left;
      flex: 1;
    }
    canvas{
      position: absolute;
      top: 0px;
      left: 0px;
    }
  </style>
</head>

<body>
  
  <div class="container">
    <!-- <input type="file" accept="video/*" /> -->
    <button id="start">请调低音量，点击开始</button>
    <div class="text-content">
      <div id="audio-left"></div>
      <div id="text"></div>
      <div id="audio-right"></div>
    </div>
  </div>
  
  <script>
    var video = document.createElement("video");
    var textDiv = document.getElementById("text");
    var audioDivRight = document.getElementById("audio-right");
    var audioDivLeft = document.getElementById("audio-left");
    var canvas = document.createElement("canvas");
    var AudioContext = window.AudioContext || window.webkitAudioContext || window.mozAudioContext;
    var audioContext = new AudioContext();//实例化

    var textAnimation = null;
    var audioAnimation = null;
    
    var time = 0, frameIndex = 0;
    var context = canvas.getContext('2d');

    let TICK = 10;
    const FRAME = 2;
    const TEXT = ["密","好","回","白","飞","口"];

    function calcText(light) {
      return TEXT[Math.floor(light/(256/TEXT.length))];
    }

    function calcBound(videoWidth, videoHeight) {
      let { innerHeight, innerWidth } = window;
      let scale = Math.min(videoHeight/innerHeight, videoWidth/innerWidth);
      return {width: Math.floor(videoWidth / scale / 60) * 60, height: videoHeight / scale};
    }

    video.addEventListener('loadeddata', function (e) {
      let { videoHeight, videoWidth } = e.path[0];
      let { width, height } = calcBound(videoWidth, videoHeight);
      canvas.width = width;
      canvas.height = height;
      canvas.style.top = `-${(height - window.innerHeight)/2}px`;
      canvas.style.left = `-${(width - window.innerWidth)/2}px`;
      TICK = width / 60;
      document.body.appendChild(canvas);
      // reloadRandomFrame();
      // window.requestAnimationFrame(videoRun);
    }, false);

    video.addEventListener('seeked', function (e) {
      context.drawImage(video, 0, 0, canvas.width, canvas.height);
      let imageData = context.getImageData(0, 0, canvas.width, canvas.height);
      let temp = ""
      for (let i = 0; i < imageData.data.length -1; i += 4 * TICK) {
        var r = imageData.data[i]
        var g = imageData.data[i + 1]
        var b = imageData.data[i + 2]
        if(i % (4 * canvas.width) === 0){
          i > 0 && (temp += "<br/>");
          i += canvas.width * 4 * TICK;
        }else{
          temp += calcText((r + g + b) / 3)
        }
      }
      textDiv.innerHTML = temp;
    }, false);

    var init = function () {
      time = 0;
      let url = `../images/test.mp4`;
      video.src = url;
      const ajax = new XMLHttpRequest();
      ajax.open("get", url, true);
      ajax.responseType = 'blob';
      ajax.onload = function() {
        var fileReader = new FileReader();
        fileReader.readAsArrayBuffer(this.response);
        fileReader.onload = function (e) {
          audioAnimation = window.requestAnimationFrame(videoRun);
          console.log(audioContext)
          audioContext.decodeAudioData(e.target.result, function (buffer) {
            var audioBufferSourceNode = audioContext.createBufferSource();
            var analyser = audioContext.createAnalyser();
            analyser.fftSize = 64;
            audioBufferSourceNode.loop = true;
            audioBufferSourceNode.connect(analyser);
            analyser.connect(audioContext.destination);
            audioBufferSourceNode.buffer = buffer;
            audioBufferSourceNode.start();
            var bufferLength = analyser.frequencyBinCount;
            var dataArray = new Uint8Array(bufferLength);
            function draw() {
              let audioText = "";
              drawVisual = requestAnimationFrame(draw);
              analyser.getByteFrequencyData(dataArray);
              for (var i = 0; i < bufferLength; i++) {
                audioText += new Array(Math.floor(dataArray[i] / 20)).fill("回").join("") + "<br/>";
              }
              audioDivRight.innerHTML = audioText;
              audioDivLeft.innerHTML = audioText;
            };
            draw();
          })
        }
      }
      ajax.send();
    };

    var startBtn = document.querySelector('#start');
    startBtn.addEventListener('click', () => {
      startBtn.style.display = "none";
      init();
    }, false);

    var playSelectedFile = function (event) {
      textAnimation && window.cancelAnimationFrame(textAnimation)
      audioAnimation && window.cancelAnimationFrame(audioAnimation)
      time = 0;
      var file = this.files[0];
      var fileURL = URL.createObjectURL(file);
      video.src = fileURL;
      var fileReader = new FileReader();
      fileReader.readAsArrayBuffer(file);
      fileReader.onload = function (e) {
        audioAnimation = window.requestAnimationFrame(videoRun);
        console.log(audioContext)
        audioContext.decodeAudioData(e.target.result, function (buffer) {
            var audioBufferSourceNode = audioContext.createBufferSource();
            var analyser = audioContext.createAnalyser();
            analyser.fftSize = 64;
            audioBufferSourceNode.loop = true;
            audioBufferSourceNode.connect(analyser);
            analyser.connect(audioContext.destination);
            audioBufferSourceNode.buffer = buffer;
            audioBufferSourceNode.start();
            var bufferLength = analyser.frequencyBinCount;
            var dataArray = new Uint8Array(bufferLength);
            function draw() {
              let audioText = "";
              drawVisual = requestAnimationFrame(draw);
              analyser.getByteFrequencyData(dataArray);
              for (var i = 0; i < bufferLength; i++) {
                audioText += new Array(Math.floor(dataArray[i] / 20)).fill("回").join("") + "<br/>";
              }
              audioDivRight.innerHTML = audioText;
              audioDivLeft.innerHTML = audioText;
            };
            draw();
          })
      }
    }

    // var input = document.querySelector('input');
    // input.addEventListener('change', playSelectedFile, false);

    function reloadRandomFrame() {
      if (!isNaN(video.duration)) {
        var rand = Math.round(Math.random() * video.duration * 1000) + 1;
        video.currentTime = rand / 1000;
      }
    }

    function videoRun() {
      time += 16.7;
      if(frameIndex >= FRAME){
        video.currentTime = (time / 1000 % video.duration);
        frameIndex = 0;
      }else  frameIndex++;
      textAnimation = window.requestAnimationFrame(videoRun);
    }

  </script>
</body>

</html>